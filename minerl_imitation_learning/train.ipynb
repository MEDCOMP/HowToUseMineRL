{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0e41c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankitagarg/.local/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from agent import Agent\n",
    "from minecraft import DummyMinecraft, Env, test_policy\n",
    "from dataset import Dataset, Transition\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from os.path import join as p_join\n",
    "from os.path import exists as p_exists\n",
    "\n",
    "from data_manager import StateManager, ActionManager\n",
    "\n",
    "from get_dataset import put_data_into_dataset\n",
    "\n",
    "import minerl\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8349ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except ModuleNotFoundError:\n",
    "    from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e754b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1bf5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = '/home/ankitagarg/minerl/minerl_imitation_learning/output_2/'\n",
    "DATASET_DIR = '/home/ankitagarg/minerl/data/'\n",
    "\n",
    "enable_cudnn = True\n",
    "train = True\n",
    "c_action_magnitude = 22.5 #magnitude of discretized camera action\n",
    "seed = 123\n",
    "scale_rewards = True\n",
    "\n",
    "learning_rate = 0.0000625\n",
    "adam_eps = 1.5e-4\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# parser.add_argument(\"--logdir\", default=\".\", type=str, help=\"used for logging and to save network snapshots\")\n",
    "net = 'deep_resnet'\n",
    "hidden_size = 1024\n",
    "dataset_path = None\n",
    "               \n",
    "trainsteps = 3000000\n",
    "augment_flip = True\n",
    "\n",
    "dataset_only_successful = False\n",
    "dataset_use_max_duration_steps = True\n",
    "dataset_continuous_action_stacking = 3\n",
    "dataset_max_reward = 256\n",
    "\n",
    "save_dataset_path = '/home/ankitagarg/minerl/minerl_imitation_learning/data/saved_dataset'\n",
    "quit_after_saving_dataset = False\n",
    "\n",
    "dueling = True\n",
    "\n",
    "add_treechop_data = True\n",
    "\n",
    "stop_time = None\n",
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2279261",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_exists(p_join(OUTPUT_DIR, 'model_last.pth')):\n",
    "    print(\"Training already finished\")\n",
    "    train = False\n",
    "if p_exists(p_join(OUTPUT_DIR, \"tmp_time.p\")):\n",
    "    print(\"Detected tmp snapshot, will continue training from there\")\n",
    "    continue_from_tmp = True\n",
    "else:\n",
    "    continue_from_tmp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3abf1da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(np.random.randint(1, 10000))\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.manual_seed(np.random.randint(1, 10000))\n",
    "torch.backends.cudnn.enabled = enable_cudnn\n",
    "device = torch.device('cuda')\n",
    "\n",
    "print(f\"Running on {device}\")\n",
    "\n",
    "state_manager = StateManager(device)\n",
    "action_manager = ActionManager(device, c_action_magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446f772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(OUTPUT_DIR)\n",
    "\n",
    "with open(p_join(OUTPUT_DIR, \"status.txt\"), 'w') as status_file:\n",
    "    status_file.write('running')\n",
    "\n",
    "# extended error exception:\n",
    "# def handle_exception(exc_type, exc_value, exc_traceback):\n",
    "\n",
    "#     with open(p_join(OUTPUT_DIR, \"status.txt\"), 'w') as status_file_:\n",
    "#         status_file_.write('error')\n",
    "\n",
    "#     writer.flush()\n",
    "#     writer.close()\n",
    "#     env.close()\n",
    "#     sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
    "\n",
    "# sys.excepthook = handle_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6398a5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankitagarg/.local/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env reset\n",
      "img, vec shapes:  torch.Size([1, 3, 64, 64]) torch.Size([1, 216])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankitagarg/minerl/minerl_imitation_learning/data_manager.py:49: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811805959/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  img_torch = torch.tensor(img_list, dtype=torch.float32, device=self.device).div_(255).permute(0, 3, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "#create the environment\n",
    "env_ = DummyMinecraft()\n",
    "env_.seed(seed)\n",
    "\n",
    "env = Env(env_, state_manager, action_manager)\n",
    "\n",
    "print(\"started env\")\n",
    "\n",
    "img, vec = env.reset()\n",
    "\n",
    "print(\"env reset\")\n",
    "\n",
    "print(\"img, vec shapes: \", img.shape, vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f2afa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = action_manager.num_action_ids_list[0]\n",
    "image_channels = img.shape[1]\n",
    "\n",
    "vec_size = vec.shape[1]\n",
    "vec_shape = vec.shape[1:]\n",
    "\n",
    "img_shape = list(img.shape[1:])\n",
    "img_shape[0] = int(img_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9c2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating dataset\n",
      "\n",
      " Adding data from MineRLObtainIronPickaxe-v0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 474/3213 [00:00<00:01, 2421.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'duration_ms': 160650, 'duration_steps': 3213, 'total_reward': 547.0, 'stream_name': 'v3_juvenile_apple_angel-7_212895-216138', 'true_video_frame_count': 3244}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3213/3213 [00:01<00:00, 3112.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 2, added: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 406/3965 [00:00<00:01, 2024.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'duration_ms': 198250, 'duration_steps': 3965, 'total_reward': 547.0, 'stream_name': 'v3_sticky_chick_pea_gnome-21_46603-50686', 'true_video_frame_count': 4085}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3965/3965 [00:01<00:00, 2817.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 2, added: 2\n",
      "\n",
      " Adding data from MineRLObtainDiamond-v0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 527/69526 [00:00<00:13, 5251.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'duration_ms': 3476300, 'duration_steps': 69526, 'total_reward': 99.0, 'stream_name': 'v3_self_reliant_fig_doppelganger-1_37451-107047', 'true_video_frame_count': 69598}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69526/69526 [00:19<00:00, 3505.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 2, added: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2018 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'duration_ms': 100900, 'duration_steps': 2018, 'total_reward': 35.0, 'stream_name': 'v3_key_nectarine_spirit-1_1619-3682', 'true_video_frame_count': 2065}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2018/2018 [00:00<00:00, 2660.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 2, added: 2\n",
      "\n",
      " Adding data from MineRLTreechop-v0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 722/1528 [00:00<00:00, 3671.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'duration_ms': 76400, 'duration_steps': 1528, 'total_reward': 64.0, 'stream_name': 'v3_content_squash_angel-3_16074-17640', 'true_video_frame_count': 1567}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1528/1528 [00:00<00:00, 3790.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 2, added: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1680 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': True, 'duration_ms': 84000, 'duration_steps': 1680, 'total_reward': 64.0, 'stream_name': 'v3_homely_string_bean_djinn-10_514-2235', 'true_video_frame_count': 1722}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1680/1680 [00:00<00:00, 4111.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 / 2, added: 2\n",
      "saved new dataset/home/ankitagarg/minerl/minerl_imitation_learning/data/saved_dataset with 21101 transitions\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(device, 2000000, img_shape, vec_shape,\n",
    "                  state_manager, action_manager,\n",
    "                  scale_rewards=scale_rewards)\n",
    "    \n",
    "if dataset_path is not None:  # default None\n",
    "\n",
    "    print(f\"loading dataset {dataset_path}\")\n",
    "    dataset.load(dataset_path)\n",
    "    print(f\"loaded dataset\")\n",
    "\n",
    "else:  # creating dataset:\n",
    "\n",
    "    assert DATASET_DIR is not None\n",
    "\n",
    "    print(\"creating dataset\")\n",
    "\n",
    "    if dataset_use_max_duration_steps:  # default: True\n",
    "        max_iron_pickaxe_duration = 6000\n",
    "        max_diamond_duration = 18000\n",
    "    else:\n",
    "        max_iron_pickaxe_duration = None\n",
    "        max_diamond_duration = None\n",
    "\n",
    "    put_data_into_dataset(\n",
    "        'MineRLObtainIronPickaxe-v0', action_manager, dataset, DATASET_DIR,\n",
    "        dataset_continuous_action_stacking,\n",
    "        dataset_only_successful,\n",
    "        max_iron_pickaxe_duration,\n",
    "        dataset_max_reward,\n",
    "        test)\n",
    "\n",
    "    put_data_into_dataset(\n",
    "        'MineRLObtainDiamond-v0', action_manager, dataset, DATASET_DIR,\n",
    "        dataset_continuous_action_stacking,\n",
    "        dataset_only_successful,\n",
    "        max_diamond_duration,\n",
    "        dataset_max_reward,\n",
    "        test)\n",
    "\n",
    "    if add_treechop_data:\n",
    "        put_data_into_dataset(\n",
    "            'MineRLTreechop-v0', action_manager, dataset, DATASET_DIR,\n",
    "            dataset_continuous_action_stacking,\n",
    "            dataset_only_successful,\n",
    "            None,\n",
    "            dataset_max_reward,\n",
    "            test)\n",
    "\n",
    "    if save_dataset_path is not None:\n",
    "        dataset.save(save_dataset_path)\n",
    "        print(f\"saved new dataset{save_dataset_path} with {dataset.transitions.index} transitions\")\n",
    "        \n",
    "    else:\n",
    "        print(\"continuing with new dataset without saving\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46448d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(dataset.transitions.index):\n",
    "    dataset.transitions.data[j] = Transition(\n",
    "        dataset.transitions.data[j].state.pin_memory(),\n",
    "        dataset.transitions.data[j].vector.pin_memory(),\n",
    "        dataset.transitions.data[j].action,\n",
    "        dataset.transitions.data[j].reward,\n",
    "        dataset.transitions.data[j].nonterminal\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ea1aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(num_actions, image_channels, vec_size, writer,\n",
    "              net, batch_size, augment_flip, hidden_size, dueling,\n",
    "              learning_rate, adam_eps, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e472df",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_time = time.time()\n",
    "if continue_from_tmp:\n",
    "    start_int = pickle.load(open(p_join(OUTPUT_DIR, \"tmp_time.p\"), \"rb\"))\n",
    "    print(f\"continuing from {start_int} trainstep\")\n",
    "    agent.load(OUTPUT_DIR, \"tmp\")\n",
    "else:\n",
    "    start_int = 0\n",
    "\n",
    "agent.train()\n",
    "\n",
    "with open(p_join(OUTPUT_DIR, \"status.txt\"), 'w') as status_file:\n",
    "    status_file.write('running training')\n",
    "\n",
    "if test:\n",
    "    trainsteps = 10\n",
    "\n",
    "fps_t0 = time.time()\n",
    "\n",
    "for i in range(start_int, trainsteps):\n",
    "# for i in range(start_int, 10000):\n",
    "\n",
    "    agent.learn(i, dataset, write=(i % 1000 == 0))\n",
    "\n",
    "    if i and i % 500000 == 0:\n",
    "        agent.save(OUTPUT_DIR, i // 500000)\n",
    "    \n",
    "#     if i and i % 5000 == 0:\n",
    "#         agent.save(OUTPUT_DIR, i // 5000)\n",
    "\n",
    "    if stop_time is not None:\n",
    "        if ((time.time() - init_time) / 60. / 60.) > stop_time:\n",
    "            print(f\"{(time.time() - init_time) / 60. / 60.} h passed, saving tmp snapshot\", flush=True)\n",
    "            agent.save(OUTPUT_DIR, \"tmp\")\n",
    "            pickle.dump(int(i), open(p_join(OUTPUT_DIR, \"tmp_time.p\"), 'wb'))\n",
    "            writer.close()\n",
    "            print('saved')\n",
    "            break\n",
    "\n",
    "    if (i+1) % 5000 == 0:\n",
    "        fps = float(i - start_int) / (time.time() - fps_t0)\n",
    "        writer.add_scalar(\"fps\", fps, i)\n",
    "\n",
    "agent.save(OUTPUT_DIR, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba218dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(p_join(OUTPUT_DIR, \"status.txt\"), 'w') as status_file:\n",
    "    status_file.write('finished')\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8672a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e2a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv] *",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
